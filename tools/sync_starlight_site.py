#!/usr/bin/env python3
import argparse
import json
import os
import re
import shutil
import tempfile
from pathlib import Path


LINK_RE = re.compile(r"\]\(([^)]+)\)")
GENERATED_BANNER_RE = re.compile(
    r"(?m)^_Generated by `tools/gen_overview_pages\.py`\.\s*Edit only inside `MANUAL:\*` blocks\._\s*$\n?"
)
OCCT_CODE_REF_RE = re.compile(r"(?<!\[)`(occt/src/[^`]+?)`")


def detect_occt_tag(repo_root: Path) -> str:
    """
    Best-effort: extract an OCCT tag from any repro oracle JSON.
    Prefers meta.occt_version, falls back to top-level occt_version.
    """
    for p in sorted((repo_root / "repros").glob("*/golden/*.json")):
        try:
            obj = json.loads(p.read_text(encoding="utf-8", errors="replace"))
        except Exception:
            continue
        version = ""
        if isinstance(obj, dict):
            meta = obj.get("meta")
            if isinstance(meta, dict):
                version = str(meta.get("occt_version") or "")
            if not version:
                version = str(obj.get("occt_version") or "")
        version = version.strip()
        if version:
            # OCCT tags are named like V7_9_3.
            return "V" + version.replace(".", "_")
    # Fall back to a reasonable default; links are still useful even if the tag isn't exact.
    return "master"


def link_occt_code_refs(md: str, *, occt_tag: str) -> str:
    base = f"https://github.com/Open-Cascade-SAS/OCCT/blob/{occt_tag}/"

    def repl(match: re.Match[str]) -> str:
        raw = match.group(1).strip()
        # Convert `occt/src/Foo.cxx` -> upstream `src/Foo.cxx`.
        rel = raw[len("occt/") :] if raw.startswith("occt/") else raw

        suffix = ""
        if "#" in rel:
            rel, frag = rel.split("#", 1)
            suffix = "#" + frag
        else:
            m = re.search(r":(\d+)$", rel)
            if m:
                rel = rel[: m.start()]
                suffix = f"#L{m.group(1)}"

        url = base + rel + suffix
        return f"[`{raw}`]({url})"

    return OCCT_CODE_REF_RE.sub(repl, md)


def rewrite_internal_markdown_links(md: str) -> str:
    def rewrite_target(target: str) -> str:
        if "://" in target:
            return target
        if target.startswith(("mailto:", "tel:", "#")):
            return target

        base = target
        suffix = ""
        for sep in ("#", "?"):
            if sep in base:
                base, rest = base.split(sep, 1)
                suffix = sep + rest
                break

        if base.endswith("/README.md") or base.endswith("/readme.md"):
            base = base[: -len("/README.md")] + "/readme/"
        elif base.endswith(".md"):
            base = base[: -len(".md")] + "/"

        return base + suffix

    def repl(match: re.Match[str]) -> str:
        target = match.group(1).strip()
        return f"]({rewrite_target(target)})"

    return LINK_RE.sub(repl, md)


def strip_section(md: str, heading: str) -> str:
    """
    Remove a markdown section by exact heading line (e.g. "## Backlog tasks"),
    up to (but not including) the next heading of same or higher level.
    """
    lines = md.splitlines(keepends=True)
    i = 0
    while i < len(lines):
        if lines[i].rstrip("\n") != heading:
            i += 1
            continue

        level = len(heading.split(" ", 1)[0])  # number of '#'
        start = i
        i += 1
        while i < len(lines):
            line = lines[i]
            if line.startswith("#"):
                hashes = len(line) - len(line.lstrip("#"))
                if hashes <= level and line[hashes : hashes + 1] == " ":
                    break
            i += 1

        del lines[start:i]
        # trim extra blank lines where the section was removed
        while start < len(lines) and lines[start].strip() == "":
            del lines[start]
        if start > 0 and lines[start - 1].strip() == "":
            while start < len(lines) and lines[start].strip() == "":
                del lines[start]
        i = start

    return "".join(lines)


def copy_file(src: Path, dst: Path, *, tmp_root: Path, src_rel: str, occt_tag: str) -> None:
    dst.parent.mkdir(parents=True, exist_ok=True)
    text = src.read_text(encoding="utf-8", errors="replace")
    text = rewrite_internal_markdown_links(text)
    text = link_occt_code_refs(text, occt_tag=occt_tag)

    # Site-specific cleanup for generated scaffolding.
    text = GENERATED_BANNER_RE.sub("", text)
    if src_rel.startswith("maps/hub-"):
        # Hubs are generated index pages; keep the “meat” and drop redundant artifact pointers.
        text = strip_section(text, "## Artifacts")
        text = strip_section(text, "## Backlog")

    if not text.startswith("---\n"):
        title = None
        for line in text.splitlines():
            line = line.strip()
            if line.startswith("# "):
                title = line[len("# ") :].strip()
                break
        if not title:
            title = dst.stem.replace("-", " ").strip() or "Document"
        # YAML frontmatter accepts JSON scalars; JSON encoding avoids quoting pitfalls.
        text = f"---\ntitle: {json.dumps(title)}\n---\n\n{text}"

    # Starlight will render the frontmatter title as the page heading.
    # Many repo docs also include an H1 (`# ...`) as the first line, which would
    # otherwise show the title twice. Strip the first H1 after frontmatter.
    if text.startswith("---\n"):
        end = text.find("\n---\n", 4)
        if end != -1:
            frontmatter = text[: end + len("\n---\n")]
            body = text[end + len("\n---\n") :]
            body_lines = body.splitlines(keepends=True)
            for i, line in enumerate(body_lines):
                if line.startswith("# "):
                    del body_lines[i]
                    if i < len(body_lines) and body_lines[i].strip() == "":
                        del body_lines[i]
                    body = "".join(body_lines)
                    text = frontmatter + body
                    break

    # Site-specific pruning: keep backlog tracking out of the rendered docs.
    text = strip_section(text, "## Backlog tasks")

    # Write atomically to avoid transient partial reads during Astro's file-watching.
    # Keep temp files OUT of the docs tree so Starlight doesn't accidentally index them.
    tmp_root.mkdir(parents=True, exist_ok=True)
    target_mode = 0o644
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(
            mode="w",
            encoding="utf-8",
            dir=tmp_root,
            prefix="sync-",
            suffix=".tmp",
            delete=False,
        ) as f:
            tmp_path = Path(f.name)
            f.write(text)
        os.chmod(tmp_path, target_mode)
        os.replace(tmp_path, dst)
    finally:
        if tmp_path and tmp_path.exists():
            tmp_path.unlink(missing_ok=True)


def copy_glob(root: Path, pattern: str, dest_root: Path, *, tmp_root: Path, occt_tag: str) -> int:
    count = 0
    for src in sorted(root.glob(pattern)):
        if not src.is_file():
            continue
        rel = src.relative_to(root)
        copy_file(src, dest_root / rel, tmp_root=tmp_root, src_rel=str(rel), occt_tag=occt_tag)
        count += 1
    return count


def write_text_atomic(dst: Path, text: str, *, tmp_root: Path) -> None:
    dst.parent.mkdir(parents=True, exist_ok=True)
    tmp_root.mkdir(parents=True, exist_ok=True)
    target_mode = 0o644
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(
            mode="w",
            encoding="utf-8",
            dir=tmp_root,
            prefix="sync-",
            suffix=".tmp",
            delete=False,
        ) as f:
            tmp_path = Path(f.name)
            f.write(text)
        os.chmod(tmp_path, target_mode)
        os.replace(tmp_path, dst)
    finally:
        if tmp_path and tmp_path.exists():
            tmp_path.unlink(missing_ok=True)


def write_fillets_oracle_explorer(
    *,
    repo_root: Path,
    dest_root: Path,
    tmp_root: Path,
    occt_tag: str,
) -> None:
    oracle_path = repo_root / "repros" / "lane-fillets" / "golden" / "fillets.json"
    if not oracle_path.is_file():
        return
    oracle_json = oracle_path.read_text(encoding="utf-8", errors="replace")
    # Avoid accidentally closing the script tag if the JSON ever contains "</script>".
    oracle_json = oracle_json.replace("</", "<\\/")

    md = f"""---
title: "Fillets Oracle Explorer"
---

This page is generated by `tools/sync_starlight_site.py` from:
- Oracle: `{oracle_path.relative_to(repo_root)}`

<div id="fillets-oracle-explorer" data-occt-tag="{occt_tag}"></div>
<script type="application/json" id="fillets-oracle-json">
{oracle_json}
</script>
<script>
(() => {{
  const root = document.getElementById('fillets-oracle-explorer');
  const script = document.getElementById('fillets-oracle-json');
  if (!root || !script) return;

  let data;
  try {{
    data = JSON.parse(script.textContent || '{{}}');
  }} catch (e) {{
    root.textContent = 'Failed to parse oracle JSON.';
    return;
  }}

  const cases = (data && data.cases) || {{}};
  const names = Object.keys(cases).sort();
  if (!names.length) {{
    root.textContent = 'No cases found in oracle JSON.';
    return;
  }}

  const el = (tag, attrs = {{}}, children = []) => {{
    const node = document.createElement(tag);
    for (const [k, v] of Object.entries(attrs)) {{
      if (v === null || v === undefined) continue;
      if (k === 'class') node.className = v;
      else node.setAttribute(k, String(v));
    }}
    for (const child of children) {{
      if (child === null || child === undefined) continue;
      node.appendChild(typeof child === 'string' ? document.createTextNode(child) : child);
    }}
    return node;
  }};

  const fmt = (v) => {{
    if (v === null || v === undefined) return '—';
    if (typeof v === 'boolean') return v ? 'true' : 'false';
    if (typeof v === 'number') return Number.isFinite(v) ? String(v) : '—';
    if (typeof v === 'string') return v || '—';
    return JSON.stringify(v);
  }};

  const toList = (obj) => {{
    if (!obj || typeof obj !== 'object') return '—';
    const entries = Object.entries(obj);
    if (!entries.length) return '—';
    return entries.map(([k, v]) => `${{k}}: ${{v}}`).join(', ');
  }};

  const renderCase = (name) => {{
    const c = cases[name] || {{}};
    const build = c.build || {{}};
    const result = c.result || {{}};
    const contours = Array.isArray(build.contours) ? build.contours : [];

    const summaryRows = [
      ['kind', c.kind],
      ['is_done', build.is_done],
      ['did_throw', build.did_throw],
      ['exception', build.exception],
      ['nb_contours', build.nb_contours],
      ['nb_faulty_contours', build.nb_faulty_contours],
      ['nb_faulty_vertices', build.nb_faulty_vertices],
      ['has_result', build.has_result],
      ['result.is_valid', result.is_valid],
      ['result.counts', result.counts ? `solids=${{result.counts.solids}}, faces=${{result.counts.faces}}, edges=${{result.counts.edges}}, vertices=${{result.counts.vertices}}` : null],
      ['computed surfaces (per contour)', contours.length ? '' : '—'],
    ];

    const summary = el('table', {{ class: 'sl-markdown-content' }}, [
      el('tbody', {{}}, summaryRows.map(([k, v]) => el('tr', {{}}, [
        el('td', {{}}, [String(k)]),
        el('td', {{}}, [fmt(v)]),
      ]))),
    ]);

    const contourTable = el('table', {{ class: 'sl-markdown-content' }}, [
      el('thead', {{}}, [
        el('tr', {{}}, [
          el('th', {{}}, ['ic']),
          el('th', {{}}, ['nb_edges']),
          el('th', {{}}, ['stripe_status']),
          el('th', {{}}, ['computed_surface_types']),
        ]),
      ]),
      el('tbody', {{}}, contours.map((row) => el('tr', {{}}, [
        el('td', {{}}, [fmt(row.ic)]),
        el('td', {{}}, [fmt(row.nb_edges)]),
        el('td', {{}}, [fmt(row.stripe_status_name || row.stripe_status)]),
        el('td', {{}}, [toList(row.computed_surface_types)]),
      ]))),
    ]);

    return el('div', {{}}, [
      el('h3', {{}}, [name]),
      summary,
      el('h4', {{}}, ['Contours']),
      contourTable,
    ]);
  }};

  const select = (id, label, initial) => {{
    const s = el('select', {{ id }}, names.map((n) => el('option', {{ value: n, selected: n === initial ? 'selected' : null }}, [n])));
    const wrap = el('label', {{ style: 'display:block; margin: 0.5rem 0;' }}, [
      el('span', {{ style: 'display:block; font-weight: 600; margin-bottom: 0.25rem;' }}, [label]),
      s,
    ]);
    return [wrap, s];
  }};

  const [primaryWrap, primarySel] = select('fillets-case-primary', 'Case', names[0]);
  const [compareWrap, compareSel] = select('fillets-case-compare', 'Compare (optional)', names.length > 1 ? names[1] : names[0]);

  const out = el('div', {{}}, []);
  const render = () => {{
    out.replaceChildren();
    out.appendChild(el('div', {{ style: 'display:grid; grid-template-columns: 1fr; gap: 1rem;' }}, [
      renderCase(primarySel.value),
      (compareSel.value && compareSel.value !== primarySel.value) ? renderCase(compareSel.value) : el('div', {{}}, []),
    ]));
  }};

  primarySel.addEventListener('change', render);
  compareSel.addEventListener('change', render);

  root.replaceChildren(
    el('p', {{}}, ['Pick a case and optionally compare it to another. Data comes from the repo oracle JSON.']),
    primaryWrap,
    compareWrap,
    out,
  );
  render();
}})();
</script>
"""

    dst = dest_root / "walkthroughs" / "fillets-explorer.md"
    write_text_atomic(dst, md, tmp_root=tmp_root)


def main() -> int:
    ap = argparse.ArgumentParser()
    ap.add_argument("--root", default=".", help="repo root (default: .)")
    ap.add_argument("--site", default="site", help="starlight site dir (default: site)")
    ap.add_argument(
        "--dest-subdir",
        default="occt",
        help="subdirectory under site docs to populate (default: occt)",
    )
    ap.add_argument(
        "--clean",
        action="store_true",
        help="delete and recreate destination subdir before syncing",
    )
    args = ap.parse_args()

    repo_root = Path(args.root).resolve()
    site_root = (repo_root / args.site).resolve()

    docs_root = site_root / "src" / "content" / "docs"
    if not docs_root.is_dir():
        raise SystemExit(f"Missing Starlight docs dir: {docs_root}")

    dest_root = docs_root / args.dest_subdir
    if args.clean and dest_root.exists():
        shutil.rmtree(dest_root)
    dest_root.mkdir(parents=True, exist_ok=True)
    tmp_root = site_root / ".sync_tmp"
    occt_tag = detect_occt_tag(repo_root)

    # Landing page for the OCCT section.
    overview_src = repo_root / "notes" / "overview.md"
    overview_dst = dest_root / "index.md"
    if not overview_src.is_file():
        raise SystemExit(f"Missing source overview: {overview_src}")
    copy_file(overview_src, overview_dst, tmp_root=tmp_root, src_rel="overview.md", occt_tag=occt_tag)

    copied = 0
    copied += copy_glob(repo_root / "notes", "maps/*.md", dest_root, tmp_root=tmp_root, occt_tag=occt_tag)
    copied += copy_glob(repo_root / "notes", "dossiers/*.md", dest_root, tmp_root=tmp_root, occt_tag=occt_tag)
    copied += copy_glob(
        repo_root / "notes" / "walkthroughs",
        "*.md",
        dest_root / "walkthroughs",
        tmp_root=tmp_root,
        occt_tag=occt_tag,
    )
    copied += copy_glob(repo_root / "repros", "*/README.md", dest_root / "repros", tmp_root=tmp_root, occt_tag=occt_tag)
    copied += copy_glob(
        repo_root / "backlog",
        "docs/*.md",
        dest_root / "backlog",
        tmp_root=tmp_root,
        occt_tag=occt_tag,
    )

    # Site-only generated interactive pages (not present in repo docs).
    try:
        write_fillets_oracle_explorer(repo_root=repo_root, dest_root=dest_root, tmp_root=tmp_root, occt_tag=occt_tag)
    except Exception:
        # Don't fail sync if the interactive helper generation fails; the core docs are more important.
        pass

    print(f"[ok] Synced {copied + 1} markdown files into {dest_root} (occt tag: {occt_tag})")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
